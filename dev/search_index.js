var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"API","title":"API Reference","text":"","category":"section"},{"location":"api/#MatrixFreeRandomizedLinearAlgebra.reigen_hermitian-Tuple{Any, Int64}","page":"API","title":"MatrixFreeRandomizedLinearAlgebra.reigen_hermitian","text":"reigen_hermitian(operator, num_components;\n                 num_oversamples=num_components,\n                 num_power_iterations=(num_components < 0.1 * minimum(size(operator)) ? 14 : 8),\n                 sample_vec=similar(operator, eltype(operator), 0))\n\nCompute a randomized eigendecomposition of a Hermitian matrix-like operator.\n\nThis routine finds approximate leading eigenvalues and eigenvectors of a Hermitian operator operator using randomized subspace iteration. It first builds an approximate invariant subspace via a randomized range finder and then computes the exact eigendecomposition of operator restricted to that subspace.\n\nArguments\n\noperator: Hermitian linear operator (self-adjoint with respect to the standard inner product), supporting size(operator) and operator * X.\nnum_components::Int: Number of leading eigenpairs to approximate.\n\nKeyword arguments\n\nnum_oversamples::Int = num_components: Oversampling parameter p; the sketch dimension is num_components + p.\nnum_power_iterations::Int: Number of power iterations used in the Hermitian range finder. Defaults to 14 for relatively small ranks (when num_components < 0.1 * min(size(operator))) and 8 otherwise. Larger values improve separation of clustered eigenvalues.\nsample_vec::AbstractVector: Prototype vector used for allocating random test matrices. Controls whether temporaries live on CPU or GPU.\n\nReturns\n\nAn Eigen object E such that\n\noperator * E.vectors ≈ E.vectors * Diagonal(E.values)\n\nwith length(E.values) == num_components (or fewer if the effective numerical rank is smaller). Eigenvalues are sorted in descending order.\n\n\n\n\n\n","category":"method"},{"location":"api/#MatrixFreeRandomizedLinearAlgebra.reigvals_hermitian-Tuple{Any, Int64}","page":"API","title":"MatrixFreeRandomizedLinearAlgebra.reigvals_hermitian","text":"reigvals_hermitian(operator, num_components;\n                  num_oversamples=num_components,\n                  num_power_iterations=(num_components < 0.1 * minimum(size(operator)) ? 14 : 8),\n                  sample_vec=similar(operator, eltype(operator), 0))\n\nCompute approximate leading eigenvalues of a Hermitian matrix-like operator.\n\nThis routine finds approximate leading eigenvalues of a Hermitian operator operator using randomized subspace iteration. It first builds an approximate invariant subspace via a randomized range finder and then computes the exact eigenvalues of operator restricted to that subspace.\n\nArguments\n\noperator: Hermitian linear operator (self-adjoint with respect to the   standard inner product), supporting size(operator) and operator * X.\nnum_components::Int: Number of leading eigenvalues to approximate.\n\nKeyword arguments\n\nnum_oversamples::Int = num_components: Oversampling parameter p; the sketch dimension is num_components + p.\nnum_power_iterations::Int:   Number of power iterations used in the Hermitian range finder. Defaults to 14   for relatively small ranks (when num_components < 0.1 * min(size(operator)))   and 8 otherwise. Larger values improve separation of clustered eigenvalues.\nsample_vec::AbstractVector:   Prototype vector used for allocating random test matrices. Controls whether   temporaries live on CPU or GPU.\n\nReturns\n\nA vector of approximate leading eigenvalues evals such that\n\noperator * v ≈ evals[i] * v\n\nfor the corresponding eigenvector v (not returned here), with length(evals) == num_components (or fewer if the effective numerical rank is smaller). Eigenvalues are sorted in descending order.\n\nThis can be significantly cheaper than reigen_hermitian if only eigenvalues are needed.\n\n\n\n\n\n","category":"method"},{"location":"api/#MatrixFreeRandomizedLinearAlgebra.rsvd-Tuple{Any, Int64}","page":"API","title":"MatrixFreeRandomizedLinearAlgebra.rsvd","text":"rsvd(operator, num_components; num_oversamples=num_components,\n     num_power_iterations=(num_components < 0.1 * minimum(size(operator)) ? 7 : 4),\n     sample_vec=similar(operator, eltype(operator), 0))\n\nCompute a randomized low-rank singular value decomposition (SVD) of a matrix-like linear operator.\n\nThis implements a standard randomized SVD with Gaussian test vectors, oversampling, and power iteration. It is intended for large, possibly matrix-free operators where forming a dense matrix is expensive.\n\nArguments\n\noperator: A linear operator acting like an AbstractMatrix, supporting size(operator), operator * X, and operator' * X. This may be a dense matrix, a sparse matrix, a GPU matrix (CuMatrix), or a matrix-free object (e.g. from LinearMaps.jl).\nnum_components::Int: Target rank k for the approximation.\n\nKeyword arguments\n\nnum_oversamples::Int = num_components: Number of oversampling vectors p. The effective sketch dimension is k + p. Larger oversampling improves accuracy at the cost of extra multiplies.\nnum_power_iterations::Int: Number of power-iteration refinement steps. If num_components is less than 10% of the smaller dimension of operator, the default is 7; otherwise 4. Increasing this improves spectral separation for slow-decaying singular values but increases cost by additional passes over operator and operator'.\nsample_vec::AbstractVector: Prototype vector used to control allocation of random test matrices. By default, similar(operator, eltype(operator), 0) is used so that temporary arrays are allocated on the same device/storage as operator. You can pass a vector living on a different device (e.g. a CuVector) to force all temporaries onto that device.\n\nReturns\n\nA LinearAlgebra.SVD object svd such that\n\nsvd.U * Diagonal(svd.S) * svd.Vt ≈ operator\n\nwith length(svd.S) == num_components (or fewer is the effective numerical rank is smaller).\n\n\n\n\n\n","category":"method"},{"location":"api/#MatrixFreeRandomizedLinearAlgebra.rsvdvals-Tuple{Any, Int64}","page":"API","title":"MatrixFreeRandomizedLinearAlgebra.rsvdvals","text":"rsvdvals(operator, num_components; num_oversamples=num_components,\n         num_power_iterations=(num_components < 0.1 * minimum(size(operator)) ? 7 : 4),\n         sample_vec=similar(operator, eltype(operator), 0))\n\nCompute the leading singualr values of a matrix-like poerator using randomized SVD techniques, without explcitly forming the singular vectors.\n\nThis has the same interface and algorithmic structure as rsvd, but only returns the approximate singualr values.\n\nArguments\n\noperator: A linear operator acting like an AbstractMatrix, supporting size(operator), operator * X, and operator' * X. This may be a dense matrix, a sparse matrix, a GPU matrix (CuMatrix), or a matrix-free object (e.g. from LinearMaps.jl).\nnum_components::Int: Target number of singular values k to compute.\n\nKeyword arguments\n\nnum_oversamples::Int = num_components: Number of oversampling vectors p. The effective sketch dimension is k + p. Larger oversampling improves accuracy at the cost of extra multiplies.\nnum_power_iterations::Int:   Number of power-iteration refinement steps. If num_components is less than   10% of the smaller dimension of operator, the default is 7; otherwise 4.   Increasing this improves spectral separation for slow-decaying singular   values but increases cost by additional passes over operator and   operator'.\nsample_vec::AbstractVector: Prototype vector used to control allocation of random test matrices. By default, similar(operator, eltype(operator), 0) is used so that temporary arrays are allocated on the same device/storage as operator. You can pass a vector living on a different device (e.g. a CuVector) to force all temporaries onto that device.\n\nReturns\n\nA vector of length num_components (or fewer if the effective numerical rank is smaller) containing the leading singular values of operator.\n\nThis can be significantly cheaper (in memory and computation) to use than rsvd when only singular values are needed.\n\n\n\n\n\n","category":"method"},{"location":"#MatrixFreeRandomizedLinearAlgebra.jl","page":"Home","title":"MatrixFreeRandomizedLinearAlgebra.jl","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"MatrixFreeRandomizedLinearAlgebra.jl is a Julia package that provides efficient implementations of randomized algorithms for linear algebra tasks, such as matrix approximations and singular value decompositions. The package is designed to work with large-scale matrices in a matrix-free manner, meaning that it does not require explicit storage of the entire matrix.\n\nPages = [\"api.md\"]","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"You can install MatrixFreeRandomizedLinearAlgebra.jl using Julia's package manager:\n\n] add MatrixFreeRandomizedLinearAlgebra","category":"section"},{"location":"#Usage-Example","page":"Home","title":"Usage Example","text":"Below is a simple example of how to use MatrixFreeRandomizedLinearAlgebra.jl to compute a randomized SVD of a matrix:\n\nusing MatrixFreeRandomizedLinearAlgebra\n\nA = randn(100, 50) # Some matrix we want to approximate\ntarget_rank = 10\nU, S, Vt = randomized_svd(A, target_rank) # Compute the randomized SVD\nrel_norm = opnorm(A - U * Diagonal(S) * Vt) / opnorm(A) # Compute relative error\nprintln(\"Relative error of the approximation: \", rel_norm)","category":"section"}]
}
